# Repo Interview Prepper

Repo Interview Prepper is an AI-powered web application designed to help developers prepare for technical interviews. By analyzing a specific GitHub repository, the tool generates tailored interview questionsâ€”ranging from architectural decisions to specific code implementationsâ€”simulating a real-world technical deep dive.

## ğŸŒ Website

Try it out: **[repo-interview-prepper.vercel.app](https://repo-interview-prepper.vercel.app)**

## ğŸ¬ Demo

![Repo Interview Prepper Demo - Analyzing a GitHub repository](./demo.gif)

## ğŸš€ Features

* **Repository Analysis**: Scans public GitHub repositories to extract file structure, README context, and key source code.
* **AI Question Generation**: Uses OpenAI's `gpt-4o-mini` to generate relevant questions based on the actual code context.
* **Adaptive Modes**: Choose between Technical, Behavioral, or Mixed question styles.
* **Mock Interview Simulation**: Interactive chat mode to practice answers with AI feedback.
* **Secure Architecture**: Uses a Vercel Serverless Function to proxy API calls, keeping your OpenAI API key hidden from the client-side.
* **Modern UI**: Fully responsive design with Dark/Light mode, glassmorphism effects, and Tailwind CSS.

## ğŸ› ï¸ Tech Stack

* **Frontend**: React 19, Vite, Tailwind CSS, Lucide React
* **Backend**: Node.js (Vercel Serverless Functions with Edge Runtime)
* **AI Integration**: OpenAI API (`gpt-4o-mini`) with SSE streaming
* **Testing**: Vitest, React Testing Library, jsdom
* **Deployment**: Vercel

## ğŸ“‚ Project Structure

```
repo-interview-prepper/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ chat.js          # Serverless backend proxy (Securely calls OpenAI)
â”‚   â””â”€â”€ chat-stream.js   # Streaming API endpoint (SSE for real-time responses)
â”œâ”€â”€ public/              # Static assets (favicon, etc.)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/      # Modular UI components
â”‚   â”‚   â”œâ”€â”€ Navbar.jsx
â”‚   â”‚   â”œâ”€â”€ RepoInput.jsx
â”‚   â”‚   â”œâ”€â”€ FileSelector.jsx
â”‚   â”‚   â”œâ”€â”€ QuestionCard.jsx
â”‚   â”‚   â”œâ”€â”€ MockChat.jsx       # Streaming chat component
â”‚   â”‚   â”œâ”€â”€ ResultsDashboard.jsx
â”‚   â”‚   â”œâ”€â”€ ContextPanel.jsx
â”‚   â”‚   â””â”€â”€ ui/
â”‚   â”‚       â””â”€â”€ SkeletonLoader.jsx
â”‚   â”œâ”€â”€ hooks/           # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ useTheme.js
â”‚   â”‚   â”œâ”€â”€ useGitHub.js
â”‚   â”‚   â””â”€â”€ useRecentSearches.js
â”‚   â”œâ”€â”€ services/        # API service layer
â”‚   â”‚   â”œâ”€â”€ github.js    # GitHub API interactions
â”‚   â”‚   â””â”€â”€ ai.js        # OpenAI API with streaming support
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ markdown.jsx # Markdown rendering utilities
â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â””â”€â”€ setup.js     # Vitest test configuration
â”‚   â”œâ”€â”€ App.jsx          # Main orchestration component
â”‚   â”œâ”€â”€ main.jsx         # Entry point
â”‚   â””â”€â”€ index.css        # Global styles & Tailwind directives
â””â”€â”€ vitest.config.js     # Testing configuration
```

## ğŸ§ª Testing

The project includes a comprehensive test suite using Vitest and React Testing Library:

```bash
# Run tests in watch mode
npm test

# Run tests once
npm run test:run

# Run tests with coverage report
npm run test:coverage

# Run tests with UI
npm run test:ui
```

**Test Coverage:**
- Unit tests for services (GitHub API, AI service)
- Hook tests (useTheme, useRecentSearches)
- Component tests (QuestionCard, RepoInput, markdown utilities)

## âš¡ Real-time Streaming

The Mock Interview Mode features **real-time streaming responses** using Server-Sent Events (SSE):
- Token-by-token AI feedback display
- Visual streaming indicator
- Abort capability for long responses

## ğŸ›¡ï¸ Architecture & Security

This project implements a Backend-for-Frontend (BFF) pattern to handle sensitive API interactions securely:

1. **Frontend (React)**: Handles user interaction, state management, and repository scanning logic.
2. **Serverless Proxy (Node.js)**: A dedicated endpoint (`/api/chat`) that acts as a secure gateway.
3. **Security**: The OpenAI API Key is stored exclusively in server-side environment variables (`OPENAI_API_KEY`), ensuring it is never exposed to the client browser.